# 날짜: 2025-07-03

## 🕛 스크럼
- **오늘 할 일**: 멀티 에이전트 구현
- **예상 이슈**: -
- **어제 회고**: 프로젝트 남은 시간을 고려해 우선 멀티 에이전트를 통한 튜닝리포트 퀄리티 개선에 집중하고 MCP를 같이 가져가는 것은 후순위로 두기로 하였다. 해당 기능이 완성되면 LLM 평가자와 같이 생성-평가 부분이 상호보완적으로 동작하는 것을 테스트 할 예정이다
- **공지사항**: 13:00 모의면접(보강)

<br>

## 💼 작업 내용
### 주제 1: 멀티 에이전트 구현
- 기존 "검색-생성"을 "분석-계획-검색-디자인-생성-검수"로 6단계의 작업으로 분할
- VRAM 사용량에 여유가 있어 기존 양자화모델에서 base 모델로 변경하고 두 모델 간 생성 퀄리티 비교


<br>

## ✊ 오늘의 도전 과제와 해결 방법
**도전과제 1**: 
- Supervisor 방식으로 멀티 에이전트 구현시 감독자 에이전트의 판단에 따른 하위 에이전트 호출
- 감독자 에이전트의 능력에 따라 결과물 여부 및 퀄리티가 결정됨
- 답변 중 중국어가 섞이거나, 제대로 에이전트를 잘 불러오지 못하는 문제

**해결방법 1**: 
- 순차적인 단계를 지니고 있으므로 Handoff 방식으로 멀티 에이전트 구현
- 이전에는 재시도 로직을 사용해 중국어 답변을 회피했지만 에이전트화 함에 따라 사용 불가
- 새로운 한국어 모델 탐색 필요

<br>

## 🤔 오늘의 회고(KPT)
- **Keep**: Ollama와 vLLM의 비교를 위해 양자화 모델을 사용했지만 서비스에서는 양자화할 필요가 없기에 베이스 모델로 교체함
- **Problem**: -
- **Try**: -

<br>

## 🔗 내용정리 및 참고자료 링크
- [멀티에이전트 노션정리](https://grizzly-crater-c04.notion.site/22175a6ebc0a80d58c47ce394731d7f3?source=copy_link)
