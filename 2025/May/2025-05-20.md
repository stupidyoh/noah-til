# 날짜: 2025-05-20

## 🕛 스크럼
- **오늘 할 일**: MCP 서버 및 클라이언트 구축
- **예상 이슈**: MCP Client 예제가 우리 서비스에 적합한 것이 없어 시간이 걸릴 것으로 예상
- **어제 회고**: GCP VM 인스턴스를 활용해 테스트 서버를 구축함. CUDA와 cuDNN 설치파일 다운로드 및 전송 과정이 상당히 느려 시간 소요가 컸음. 환경 구축 완료 후에 현재까지 개발된 API 실행한 결과 기존과 유사하게 결과물이 잘 나오는 것을 확인함

- **팀 이슈**: -
- **공지사항**: 13:25 PL미팅

<br>

## 💼 작업 내용
### 주제 1: MCP 구축
- [MCP](https://modelcontextprotocol.io/quickstart/server#system-requirements)에서 제공하는 문서 기반으로 서버 및 클라이언트 구현
- 추후 다중 서버를 사용할 것을 염두에 두었을 때 해당 기능 구현이 안되는 것을 확인
- [Langchain-mcp-adapter](https://github.com/langchain-ai/langchain-mcp-adapters) 활용시 다중 서버 연결이 가능함으로 확인
- 로컬 모델 사용과 vLLM 적용 가능한지 추가 확인 필요


<br>

## ✊ 오늘의 도전 과제와 해결 방법
- **도전과제 1**: -
- **해결방법 1**: -

<br>

## 🤔 오늘의 회고(KPT)
- **Keep**: 같은 인공지능 과정 팀원과 토의했을 때 서로의 코드를 이해할 시간이 필요하다는 것을 인지함. 이에 따라 다음주는 각자의 코드 리뷰 및 리팩터링 시간을 가질 것으로 얘기함.
- **Problem**: -
- **Try**: 로컬 모델 사용과 vLLM 적용 가능한지 추가 확인 필요

<br>

## 🔗 내용정리 및 참고자료 링크
- [노션 정리](https://grizzly-crater-c04.notion.site/MCP-1f775a6ebc0a80dcb8b6c4eb0d2683d7?pvs=4)
