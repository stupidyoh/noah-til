# 날짜: 2025-05-23

## 🕛 스크럼
- **오늘 할 일**: OpenAI Agent SDK 테스트
- **예상 이유**: 모델에 따른 용량 크기로 인해 서버 메모리 포화 문제
- **어제 회고**: Langchain-mcp-adapters에서 Ollama와 vLLM 모두 모델 서빙 적용이 가능함을 확인함. 또한, 외부 MCP 서버 툴 역시 가져와서 사용이 가능함. 다만 테스트 모델이 가벼워서인지 혹은 구성을 제대로 하지 않아서인지 답변 퀄리티는 아쉬웠음.

- **팀 이슈**: -
- **공지사항**: 15:00 멘토링

<br>

## 💼 작업 내용
### 주제 1: 모의면접 멘토링(피드백 위주로 정리)
- 1분 자기소개를 통해 나의 경험은 이렇다 그러니 이런 질문을 해달라고 유도할 수 있음
- 여러 CS 과목 중 하나는 깊이 있게 대답할 수 있어야 함
   - AI 엔지니어 분야에는 컴퓨터 구조가 연관이 깊음
   - 최근 나오는 딥러닝 칩 등에 대한 내용을 알고 있으면 도움이 될 것 같음
   - 단순히 지식을 외운 것이 아닌 보다 깊게 고민하고 공부해야만 답변할 수 있는 수준이 되어야 함
- 면접은 면접관과의 티키타카가 중요
    - 모호한 답변은 꼬리질문이 들어옴
    - 진짜 모르겠으면 솔직히 잘 모르겠다 해도 됨
    - 너무 완벽한 답변에 매몰되지 말 것

### 주제 2: OpenAI Agent SDK 테스트
- 사용 모델 변경 `Qwen/Qwen2.5-3B-Instruct` => 서버 정상 구동 확인
- agent.py 실행 => 외부 MCP 서버 툴 사용을 위한 Node.js 설치 필요
- OPENAI_API_KEY 미설정 문제 => OpenAI 서빙 모델이 아님에도 불구하고 API key가 필요하여 사용 제한

### 주제 3: 프로젝트 코드에 Langchain-MCP-Adapters 연결
- MCP 클라이언트 구현 부분을 프로젝트 서비스 모듈에 통합시키는 작업 진행
- 모델 로드 분리 완료

<br>

## ✊ 오늘의 도전 과제와 해결 방법
- **도전과제 1**: 주제 2와 동일
- **해결방법 1**: Langchain-MCP-Adapters를 사용할 것으로 최종 결정. 이전에 계획한 vLLM, 외부 MCP 서버 툴 모두 사용 가능 확인 완료

<br>

## 🤔 오늘의 회고(KPT)
- **Keep**: 인성질문 부분은 칭찬을 받았다. 하지만 내 생각엔 자신의 경험에 대해 한 번 더 정리할 필요가 있었음.
- **Problem**: CS 기초지식이 정말 중요함을 느꼈다. 답변을 못하니 모의면접 시간을 의미 없게 사용했다는 생각이 들었다.
- **Try**: 꾸준히 계속 CS 공부할 것. 특히 컴퓨터구조 쪽은 AI와 연관을 지어 깊게 해서 하나의 강점을 만들자!

<br>

## 🔗 내용정리 및 참고자료 링크
- [MCP 서버 및 클라이언트 구축 노션 정리](https://grizzly-crater-c04.notion.site/MCP-1f775a6ebc0a80dcb8b6c4eb0d2683d7?pvs=4)
