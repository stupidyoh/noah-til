# 날짜: 2025-05-13

## 🕛 스크럼
- **오늘 할 일**: 모델 추가 탐색 및 v1기능 고도화 논의
- **예상 이유**: 마일스톤 반영 여부 및 스프린트 계획 재구성
- **어제 회고**: 7B 내외의 한국어 지원 모델 및 추론시간 약 20초 내외로 스펙을 선정하고 모델 탐색중. HyperclovaX와 Kanana가 무난한 성능을 보이나 vLLM 미지원으로 아쉬운 부분이 있음. 각 모델별 장단점을 정리하고 우리 서비스에 어떤 모델이 적합한지 최종 선택할 것임. 

- **팀 이슈**: 오늘 22시 2차 QA 진행 예정
- **공지사항**: 동기 미팅은 짧고 효율적으로 진행할 것

<br>

## 💼 작업 내용
### 주제 1: 모델 추가 탐색 
- Qwen/Qwen2.5-7B-Instruct-1M, google/gemma-2-9b 등 추가 탐색
- 모델 크기, 최적화 가능 여부, 추론 시간 등 고려
- Qwen2.5(최적), EXAONE(한국어특화), HyperClovaX(경량)로 후보 선정
- 서비스 우선순위에 따라 최종 모델 선정 필요(v1 기능 최적화 후 진행)

| **모델** | **vLLM 지원여부** | 모델 로딩 시간 | **추론시간** | **모델 로딩 전체 VRAM** | **모델 추론 전체 VRAM** | **비고** |
| --- | --- | --- | --- | --- | --- | --- |
| naver-hyperclovax/HyperCLOVAX-SEED-Vision-Instruct-3B | X | 52.98 | 14.32 | 7667 | 7913 |  |
| kakaocorp/kanana-nano-2.1b-instruct | X | 26.88 | 20.86 | 4577 | 4835 |  |
| microsoft/bitnet-b1.58-2B-4T | - | - | - |  |  | 로딩 이슈 |
| meta-llama/Meta-Llama-3.1-8B-Instruct | O | 60.54 | 22.56 | 15743 | 16079 |  |
| Qwen/Qwen3-8B | O | 95.97 | 56.45 | 16049 | 16521 |  |
| Qwen/Qwen2.5-7B-Instruct-1M | O | 100.69 | 17.61 | 14951 | 15239 |  |
| google/gemma-2-9b | O | 126.35 | 61.57 | - | - | generate 인자 추가로 필요 |
| LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct | O | 99.02 | 18.38 | 17815 | 18903 |  |

### 주제 2: v1 기능 고도화(사용자 등록 api)
- 30회 요청(동시요청 3)에 대해 최대 응답시간 4.78초, 평균 응답시간 3.46초 소요
- 이후 추가로 30회 요청에 대해 최대 응답시간 7.63초, 평균 응답시간 6.14초 소요
- 이에 따른 이전에 개선한 코드를 적용해 다시 부하테스트 진행
- (최초 30명) 최대 응답시간 4.54초, 평균 응답시간 3.34초
- (추가 30명) 최대 응답시간 7.46초, 평균 응답시간 6.05초
- 30명 요청 기준 7.55% / 5.31% 개선
- 추후 개선사항
   - 중복 임베딩 문제
   - 동기적 계산 문제
   - 역방향 유사도 업데이트
   - ChromaDB 접근 효율 개선
 
### 주제 3: v1 기능 고도화(매칭 추천 api)
- 부하테스트 확인 결과 동시요청이 증가할수록 응답시간 증가
- 벡터DB를 id, 메타데이터로 두 번 탐색하는 부분 식별
- 코드레벨에서 검증하지 않고 에러처리하는 방식으로 수정 권유(khloe)

<br>

## ✊ 오늘의 도전 과제와 해결 방법
- **도전과제 1**: 부하테스트로 동일한 환경 및 설정으로 사용자 등록 api를 실험한 결과 유의미한 개선률을 보이지 않음
- **해결방법 1**: 추가 식별된 문제들에 대해서 개선 후 다시 테스트 진행 예정

<br>

## 🤔 오늘의 회고(KPT)
- **Keep**: v1 기능을 개선하면서 부하테스트를 매번 클라우드에 요청하는 작업이 번거로워 직접 하려고 하였으나 서버에서의 테스트 소요가 각 과정별로 있음. 논의 결과 현 체제를 유지하되 한 스레드에서 요청과 결과 확인을 하도록 협의함
- **Problem**: 부하테스트 진행 후 개선이 미미하여 추가 개선 필요
- **Try**: 식별된 문제들에 대해 추가 개선 시도 후 부하테스트 진행

<br>

## 🔗 내용정리 및 참고자료 링크
- [refactor: 매칭 점수 계산 로직을 최적화된 버전으로 교체 #51](https://github.com/100-hours-a-week/2-hertz-ai/pull/51)
