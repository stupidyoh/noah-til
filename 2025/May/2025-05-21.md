# 날짜: 2025-05-21

## 🕛 스크럼
- **오늘 할 일**: MCP 서버 및 클라이언트 구축
- **예상 이유**: Langchain 구조와 vLLM 구조 양립이 가능한지 확인 필요
- **어제 회고**: MCP 공식 튜토리얼로는 다중 서버를 활용한 클라이언트 구현이 어려웠음. Langchain에서 제공하는 프레임워크를 활용하면 이를 해결 가능. 하지만 vLLM과 같이 사용이 가능한지 확인이 필요했음.

- **팀 이슈**: -
- **공지사항**: 10:00 타운홀미팅

<br>

## 💼 작업 내용
주제 1: MCP 설정 및 환경 구성
* uv 패키지 매니저 설치 (가상환경 생성 및 관리)
* MCP 관련 라이브러리 설치 (mcp[cli], fastmcp, langchain 등)

주제 2: LangGraph MCP Agents 테스트
* LangGraph와 MCP 어댑터 설치 및 테스트
* 초기 테스트에서 HuggingFace 모델과 호환성 문제 발생
   * AttributeError: 'HuggingFaceHub' object has no attribute 'bind_tools'
* Google API 키 설정 후 성공적으로 다중 MCP 서버(Math, Weather) 테스트 완료

주제 3: 로컬 LLM 테스트
* HuggingFace 엔드포인트로 테스트 → 'bind_tools' 속성 부재로 실패
* FastMCP + 로컬 LLM 테스트 성공
   * meta-llama/Llama-3.2-1b-instruct 모델 사용
   * Function Calling 지원 모델만 동작함을 확인

주제 4: Ollama + LangChain-MCP-Adapters 테스트
* Ollama 설치 및 구성
* 테스트 모델: qwen2.5:3b 및 llama3.2:3b
* 다양한 질문에 대한 응답 테스트 수행
* 응답 퀄리티는 낮음

<br>

## ✊ 오늘의 도전 과제와 해결 방법
- **도전과제 1**: 설계 단계에서 결정한 최종 모델 Qwen, vLLM을 통한 모델 최적화, GPU 서버 사용, 외부 MCP 서버 툴 사용 등을 만족시키는 방식 찾기가 어려웠음
- **해결방법 1**: MCP와 FastMCP에서 제공하는 기본 튜토리얼을 기준으로 테스트했을 때는 요구 조건을 충족시키지 못하는 모습을 확인함. 추가로 자료조사 중 Agent Framework로 Langchain-MCP-Adapters와 OpenAI Agent SDK를 발견. 각 프레임워크별 장단점이 있고 요구사항을 모두 만족시키는 것은 현재로서는 불가함. 양쪽 모두 테스트 후 우선순위에 따라 어떤 방식을 채택할지 결정할 예정

<br>

## 🤔 오늘의 회고(KPT)
- **Keep**: 공식문서와 다른 사람들이 구현한 오픈소스를 살펴보며 어떤 방식이 우리 서비스에 적합할지 탐색함
- **Problem**: 이것저것 테스트를 하고 결과가 좋지 않다보니 문서화에 신경을 쓰지 못했음.
- **Try**: 미래의 나 그리고 팀원을 위해서라도 문서로 깔끔하게 정리하도록 하자. 설치과정, 테스트과정, 해당 방식의 정의, 특징, 왜 사용하는지 등 명확한 이해도 동반할 것

<br>

## 🔗 내용정리 및 참고자료 링크
- [노션 정리](https://grizzly-crater-c04.notion.site/MCP-1f775a6ebc0a80dcb8b6c4eb0d2683d7?pvs=4)
