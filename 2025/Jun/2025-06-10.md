# 날짜: 2025-06-10

## 🕛 스크럼
- **오늘 할 일**: vLLM/Ollama 테스트 문서화 및 API 연동
- **예상 이유**: -
- **어제 회고**: 처음 vLLM을 Langchain에 물려서 사용하려고 했을 때 에러가 발생하는 것을 보고 안되는 것인가 했는데 관련 자료가 많이 없음에도 해결할 수 있는 방법을 찾아 테스트해 볼 수 있었다. vLLM이 가지는 장점을 확실히 비교해 볼 수 있었으나 확실히 무겁다는 인상을 받았다. 추후 확장에 있어 걸리는 점은 없을지 검토가 필요하다.

- **팀 이슈**: -
- **공지사항**: 중간배포를 위한 QA 진행(00시 예정)

<br>

## 💼 작업 내용
### 주제 1: vLLM/Ollama 테스트 문서화
- Github 팀 Wiki에 테스트 내용 정리
- 하단에 링크 참고

### 주제 2: pm2 테스트
- zero.lee(클라우드)와 함께 vLLM 서버를 별도로 띄우기 위한 pm2 테스트
- 테스트 과정에서는 vLLM 서버를 별도의 터미널에서 실행
- 모델 불러오기가 완료될 때 비즈니스 로직을 실행하기 위해 pm2를 통해 백그라운드 실행
- 코드 레벨에서 별도의 수정사항 없이 모델이 완전히 불러와질 때까지 재시도


<br>

## ✊ 오늘의 도전 과제와 해결 방법
**도전과제 1**: 
- 복잡한 프롬프트 요청에 따른 MCP 도구 미사용 문제

**해결방법 1**:
- 프롬프트 내부에 MCP를 활용하기 위한 동작 순서 및 지침 추가하였으나 기존의 튜닝 리포트 생성을 위한 프롬프트가 더 지배적임에 따라 MCP 도구 호출을 하지 않음
- (시도예정) - Tool 사용에 우선순위 적용 
    ```
    "1. 먼저 검색 수행"
    "2. 그다음 JSON 형식으로 정리"
    ```
    
- (시도예정)구체적이고 단순명확한 요청
    ```
    # ❌ 복잡한 요청
    "사용자 정보를 분석하여 관련 키워드 파악 후 검색하여..."
    
    # ✅ 단순한 요청  
    "판교 날씨와 기술 트렌드를 검색해주세요"
    ```

<br>

## 🤔 오늘의 회고(KPT)
- **Keep**: 카카오멘토링과 발표동아리 간에 얻은 내용을 바탕으로 우리 서비스에 LLM 평가 및 프롬프트 관리를 추가 도입할 예정. 이에 대해 팀원과 상의 후 차주 스프린트 계획에 반영함.
- **Problem**: MCP 연결을 통한 결과 생성이 생각보다 긴 시간 소요 중. 시도예정 방안이 안 될 경우 조언을 구할 필요 있음.
- **Try**: 프롬프트 버전 관리를 위한 Langfuse와 LLM-as-a-Judge에 대한 자료조사 및 공부 필요

<br>

## 🔗 내용정리 및 참고자료 링크
- [vLLM vs. Ollama 성능 비교 테스트](https://github.com/100-hours-a-week/2-hertz-wiki/wiki/%5BAI%5D-vLLM-vs.-Ollama-%EC%84%B1%EB%8A%A5-%EB%B9%84%EA%B5%90-%ED%85%8C%EC%8A%A4%ED%8A%B8)
- [노션 정리](https://grizzly-crater-c04.notion.site/MCP-20e75a6ebc0a800d8ddfdfda08dd65da?source=copy_link)
