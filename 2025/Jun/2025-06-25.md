# 날짜: 2025-06-25

## 🕛 스크럼
- **오늘 할 일**: LLM 평가 지표 추가 테스트 및 생성 프롬프트 튜닝
- **예상 이슈**: Claude, chatgpt 생성 결과를 변별한 지표 추가
- **어제 회고**: gemini 무료 티어로 테스트 중 일일한도량 초과로 tier 1으로 업그레이드 후 연결한 프로젝트 내에서만 사용 가능함을 확인하는 데에 시간이 일부 소요됐다. 한편, 지표 수립에 시간을 너무 사용하고 있기 때문에 이후 단계를 같이 진행하면서 수정해나갈 필요가 있음.
- **공지사항**: -

<br>

## 💼 작업 내용
### 주제 1: LLM 평가 지표 추가 테스트
1. 평가 결과 구체화(개인화, 흥미도)를 통한 쳬계적 사고 유도
   - claude의 경우, 표준편차 2.24로 이전 테스트(표준편차 2.75) 대비 평가 일관성이 향상
   - Qwen도 표준편차 부분에서 일관성 향상됨을 보임
2. 평가 결과 출력 방식에서 단계별 사고 추가 & 개인화 지표 규칙 강화
   - 표준편차가 크게 개선되어 점수 변동성이 적어진 것을 확인
   - 하지만 세부평가지표를 보면 개인화와 공감대 부분이 거의 점수를 받지 못함
   - 실제로 제3자의 시선에서 튜닝 리포트를 읽는데 개인화를 나의 이야기로 몰입하는 시점에 평가함에 따라 발생한 문제임
   - 이에 따라 해당 평가방식은 폐기
3. 개인화 및 공감 평가지표 수정/구체화 & 스토리텔링 중심으로 평가원칙 수정
   - claude의 경우, 총점에 대해서는 표준편차가 높지만 세부지표별롤 봤을 때는 각 지표별로 점수 변동이 1점 내외
   - 이에 따라 생성 프롬프트 개선으로 넘어감

<br>

## ✊ 오늘의 도전 과제와 해결 방법
**도전과제 1**: 
- 

**해결방법 1**: 
- 

<br>

## 🤔 오늘의 회고(KPT)
- **Keep**: 각 테스트별로 프롬프트, 평가결과, 평가분석으로 정리하여 기록함
- **Problem**: 한 번 평가시 60번의 Gemini 호출이 있어 프롬프트를 한 번 바꿀 때마다 테스트에 오랜 시간이 걸림. 때문에 전반적으로 작업이 늘어지는 경향이 있었음.
- **Try**: 이후에도 비슷한 상황에 놓인다면 코드를 좀 더 본다거나, 관련 내용을 공부하는 등 해당 시간을 의미있게 쓸 것

<br>

## 🔗 내용정리 및 참고자료 링크
- [LLM 평가 프롬프트 튜닝](https://grizzly-crater-c04.notion.site/21475a6ebc0a8016b662f348bd809eae?source=copy_link)
