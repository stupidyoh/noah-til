# 날짜: 2025-06-24

## 🕛 스크럼
- **오늘 할 일**: LLM 평가 지표 추가 테스트
- **예상 이슈**: Claude, chatgpt 생성 결과를 변별할 지표 추가
- **어제 회고**: 새로운 도입한 지표를 기준으로 qwen과 LLM이 생성한 결과를 변별하는 것을 확인할 수 있었다. 다만 claude와 chatgpt의 결과 모두 만점에 가깝게 평가되기 때문에 이를 변별하기 위한 추가 지표 도입 혹은 척도 수정이 필요함. 
- **공지사항**: 13:15 PL 미팅 / 매일 아침 데일리스크럼 서기 돌아가면서 작성

<br>

## 💼 작업 내용
### 주제 1: LLM 평가 지표 추가 테스트
- 이전보다 척도를 보다 엄격하게 설정함으로써 만점에 편향되는 문제를 해결하고자 함
- 만점이 지배적이었던 Claude과 chatGPT 생성 결과물의 점수가 낮아지고 두 모델 사이에 변별력 역시 생김
- Claude 생성 결과물의 경우 점수 변동성이 커 표준편차가 2.75 확인

| 모델 | 후보1 | 후보2 | 후보3 | 후보4 | 후보5 | 후보6 | 후보7 | 후보8 | 후보9 | 후보10 | 평균 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| qwen | 16 | 15 | 13 | 12 | 11 | 17 | 14 | 15 | 13 | 14 | 14.00 |
| claude | 24 | 26 | 29 | 22 | 30 | 29 | 29 | 31 | 30 | 25 | 27.50 |
| chatgpt | 23 | 23 | 23 | 24 | 24 | 25 | 25 | 30 | 27 | 24 | 24.80 |

| 모델/후보 | 반복1 | 반복2 | 반복3 | 반복4 | 반복5 | 반복6 | 반복7 | 반복8 | 반복9 | 반복10 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| qwen/후보1 | 15 | 13 | 13 | 15 | 16 | 15 | 11 | 17 | 13 | 17 |
| claude/후보1 | 28 | 25 | 29 | 28 | 22 | 28 | 23 | 23 | 21 | 25 |
| chatgpt/후보1 | 24 | 24 | 25 | 24 | 23 | 23 | 24 | 24 | 24 | 24 |

| 모델/후보 | 평균 | 표준편차 |
| --- | --- | --- |
| qwen/후보1 | 14.50 | 1.86 |
| claude/후보1 | 25.20 | 2.75 |
| chatgpt/후보1 | 23.90 | 0.54 |


<br>

## ✊ 오늘의 도전 과제와 해결 방법
**도전과제 1**: 
- LLM 평가자에 대해 편향과 변동 문제

**해결방법 1**: 
- 다양한 평가지침 및 평가지표를 통해 테스트 지속 중(미해결)

<br>

## 🤔 오늘의 회고(KPT)
- **Keep**: 졸릴 때 작업환경을 바꾸니 어느 정도 잠이 깨는 효과가 있었다. 타운홀과 워크스페이스를 병행하며 작업을 이어갈 수 있도록 하자.
- **Problem**: Gemini API 무료 티어의 일일사용한도 250건이 초과하여 GCP 프로젝트에 연결해 tier 1으로 올렸다. GCP 내에서만 사용하는 줄 모르고 찾아보다가 시간이 소요됐다.
- **Try**: 주변에 물어보고 하였지만 아는 사람이 없어 어찌 해결할 방법은 없었다. 공식문서를 보다 꼼꼼히 확인해보고 되는지 안되는지 바로 테스트 해보는 수 밖에 없다.

<br>

## 🔗 내용정리 및 참고자료 링크
- [LLM 평가 프롬프트 개선](https://grizzly-crater-c04.notion.site/21475a6ebc0a8016b662f348bd809eae?source=copy_link)
